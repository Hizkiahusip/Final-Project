{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit9682afc1dce14a5c9def90105ba5095f",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\\Users\\Kijeng\\AppData\\Local\\Programs\\Python\\Python38\\lib\\csv.py\n"
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'banjir.txt'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-714ba7dc034b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[0mtrain_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'banjir.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;31m#   menjalankan fungsi loadcorpus dan loadcorpuschar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m     \u001b[0mtoken_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbi_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtri_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquad_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m     \u001b[0mtoken_len_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadCorpusChar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbi_dict_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtri_dict_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquad_dict_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_dict_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-714ba7dc034b>\u001b[0m in \u001b[0;36mloadCorpus\u001b[1;34m(file_path, bi_dict, tri_dict, quad_dict, vocab_dict)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mword_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;31m#   memuat korpus kalimat dan di baca line per line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'banjir.txt'"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from tkinter import *\n",
    "import string\n",
    "import time\n",
    "import gc\n",
    "from math import log10\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "start_time = time.time()\n",
    "import csv\n",
    "import pandas as pd\n",
    "print(csv.__file__)\n",
    "import glob, os\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys, time\n",
    "from itertools import cycle\n",
    "\n",
    "global keyword\n",
    "# membuat koneksi\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return None\n",
    "# mengecek kalimat yang tidak ada di korpus kata\n",
    "def cekWrong(conn,inputWrong):\n",
    "    x = 0\n",
    "#   memecah inputan menjadi per kata\n",
    "    temp_l = inputWrong.split()\n",
    "    i = 0\n",
    "    j = 0\n",
    "#   Membersihkan inputan\n",
    "    for word in temp_l :\n",
    "        j = 0\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                if l == \"'\":\n",
    "                    if j+1<len(word) and word[j+1] == 's':\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                word = word.replace(l,\" \")\n",
    "#                     print(j,word[j])\n",
    "            j += 1\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "    content = \" \".join(temp_l)\n",
    "    token = content.split()\n",
    "#   cek perkata ada di korpus kata atau tidak\n",
    "    for teks in token:\n",
    "        kata.append(teks)\n",
    "        teksStemming = fetch(teks)\n",
    "        cur = conn.cursor()\n",
    "#       query untuk cek yang tidak memiliki tag\n",
    "        cur.execute('Select kata from korpus_kata where kata = (?) and tag != \"Entri tidak ditemukan\" and tag != \"tidak ditemukan kata yang dicari\" and tag != \"entri tidak ditemukan\" ',(teksStemming,))\n",
    "        a = cur.fetchone()\n",
    "        conn.commit()\n",
    "        if a==None:\n",
    "#           kaliamt yang tidak ada di korpus kata disimpan di wrong\n",
    "            wrong.append(x)\n",
    "        x= x + 1\n",
    "# fungsi untuk mengambil 3 kata sebelum kalimat singkatan\n",
    "\n",
    "def kalimatTeks(i):\n",
    "    n = wrong[i]\n",
    "    if n >= 3 :\n",
    "        temp = kata[n-3] + ' ' + kata[n-2]  + ' ' + kata[n-1]\n",
    "        input_teks.append(temp)\n",
    "    elif n == 2 :\n",
    "        temp = 's' + ' ' + kata[n-2] + ' ' + kata[n-1]\n",
    "        input_teks.append(temp)\n",
    "    elif n == 1 :\n",
    "        temp = 's' + ' ' + 's' + ' ' + kata[n-1]\n",
    "        input_teks.append(temp)\n",
    "    elif n == 0 :\n",
    "        temp = 's' + ' ' + 's' + ' ' + 's'\n",
    "        input_teks.append(temp)\n",
    "    print(n)\n",
    "# fungsi membersihkan kalimat\n",
    "def removePunctuations(sen):\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "    j = 0\n",
    "#   menghilangkan tanda baca dan membuat jadi huruf kecil\n",
    "    for word in temp_l :\n",
    "        j = 0\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                if l == \"'\":\n",
    "                    if j+1<len(word) and word[j+1] == 's':\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                word = word.replace(l,\" \")\n",
    "            j += 1\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "    content = \" \".join(temp_l)\n",
    "    return content\n",
    "# memuat korpus kalimat untuk menjadi dataset dan menghitung jumlah dari quadgram, trigram dan bigram \n",
    "def loadCorpus(file_path, bi_dict, tri_dict, quad_dict, vocab_dict):\n",
    "    w1 = ''    #variabel untuk menyimpan 3 kalimat terakhir untuk token set\n",
    "    w2 = ''    #variabel untuk menyimpan 2 kalimat terakhir untuk token set\n",
    "    w3 = ''    #variabel untuk menyimpan kalimat terakhir untuk token set\n",
    "    token = []\n",
    "    word_len = 0\n",
    "#   memuat korpus kalimat dan di baca line per line\n",
    "    with open(file_path,'r', encoding=\"utf-8\") as file:\n",
    "        print(file)\n",
    "        for line in file:\n",
    "            print(line)\n",
    "#           memecah kalimat menjadi kata\n",
    "            temp_l = line.split()\n",
    "            i = 0\n",
    "            j = 0\n",
    "#           menghilangkan tanda baca dan mebuat kata menjadi huruf kecil\n",
    "            for word in temp_l :\n",
    "                j = 0\n",
    "                for l in word :\n",
    "                    if l in string.punctuation:\n",
    "                        if l == \"'\":\n",
    "                            if j+1<len(word) and word[j+1] == 's':\n",
    "                                j = j + 1\n",
    "                                continue\n",
    "                        word = word.replace(l,\" \")\n",
    "                    j += 1\n",
    "\n",
    "                temp_l[i] = word.lower()\n",
    "                i=i+1   \n",
    "            content = \" \".join(temp_l)\n",
    "            token = content.split()\n",
    "#           menghitung jumlah kata\n",
    "            word_len = word_len + len(token)  \n",
    "            if not token:\n",
    "                continue\n",
    "#           menambahkan kalimat terakhir ke variabel\n",
    "            if w3!= '':\n",
    "                token.insert(0,w3)\n",
    "#           token untuk bigrams\n",
    "            temp0 = list(ngrams(token,2))\n",
    "#           menambahkan kalimat dua terakhir ke variabel\n",
    "            if w2!= '':\n",
    "                token.insert(0,w2)\n",
    "#           token untuk trigrams\n",
    "            temp1 = list(ngrams(token,3))\n",
    "#           menambahkan kalimat tiga terakhir ke variabel\n",
    "            if w1!= '':\n",
    "                token.insert(0,w1)\n",
    "#           menambahkan kata unik ke vocaulary\n",
    "            for word in token:\n",
    "                if word not in vocab_dict:\n",
    "                    vocab_dict[word] = 1\n",
    "                else:\n",
    "                    vocab_dict[word]+= 1\n",
    "#           token untuk quadgrams\n",
    "            temp2 = list(ngrams(token,4))\n",
    "#           menghitung frekuensi dari bigram\n",
    "            for t in temp0:\n",
    "                sen = ' '.join(t)\n",
    "                bi_dict[sen] += 1\n",
    "#           menghitung frekuensi dari trigram\n",
    "            for t in temp1:\n",
    "                sen = ' '.join(t)\n",
    "                tri_dict[sen] += 1\n",
    "#           menghitung frekuensi dari quadgrams\n",
    "            for t in temp2:\n",
    "                sen = ' '.join(t)\n",
    "                quad_dict[sen] += 1\n",
    "#           menghitung panjang token\n",
    "            n = len(token)\n",
    "#           menambahkan kalimat ke variabel\n",
    "            if (n -3) >= 0:\n",
    "                w1 = token[n -3]\n",
    "            if (n -2) >= 0:\n",
    "                w2 = token[n -2]\n",
    "            if (n -1) >= 0:\n",
    "                w3 = token[n -1]\n",
    "    return word_len\n",
    "\n",
    "# memuat korpus kalimat untuk menjadi dataset character dan menghitung jumlah dari quadgram, trigram dan bigram \n",
    "def loadCorpusChar(file_path, bi_dict_char, tri_dict_char, quad_dict_char, vocab_dict_char):\n",
    "    w1_char = ''    #variabel untuk menyimpan 3 huruf terakhir untuk token set\n",
    "    w2_char = ''    #variabel untuk menyimpan 2 huruf terakhir untuk token set\n",
    "    w3_char = ''    #variabel untuk menyimpan huruf terakhir untuk token set\n",
    "    token = []\n",
    "    word_len_char = 0\n",
    "#   memuat korpus kalimat dan di baca line per line\n",
    "    with open(file_path,'r', encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "#           memecah kalimat menjadi karakter\n",
    "            temp_l_char = list(line)\n",
    "            i = 0\n",
    "            j = 0\n",
    "#           menghilangkan tanda baca dan mebuat huruf kecil\n",
    "            for char in temp_l_char :\n",
    "                j = 0\n",
    "                for l in char :\n",
    "                    if l in string.punctuation:\n",
    "                        if l == \"'\":\n",
    "                            if j+1<len(char) and char[j+1] == 's':\n",
    "                                j = j + 1\n",
    "                                continue\n",
    "                        char = char.replace(l,\" \")\n",
    "                        #print(j,word[j])\n",
    "                    j += 1\n",
    "\n",
    "                temp_l_char[i] = char.lower()\n",
    "                i=i+1   \n",
    "            content_char = \" \".join(temp_l_char)\n",
    "            token_char = content_char.split()\n",
    "#           menghitung jumlah karakter\n",
    "            word_len_char = word_len_char + len(token_char)  \n",
    "            if not token_char:\n",
    "                continue\n",
    "#           menambahkan huruf terakhir ke variabel\n",
    "            if w3_char!= '':\n",
    "                token_char.insert(0,w3_char)\n",
    "#           token untuk bigrams\n",
    "            temp0_char = list(ngrams(token_char,2))\n",
    "#           menambahkan 2 huruf terakhir ke variabel\n",
    "            if w2_char!= '':\n",
    "                token_char.insert(0,w2_char)\n",
    "#           token untuk trigrams\n",
    "            temp1_char = list(ngrams(token_char,3))\n",
    "#           menambahkan 3 huruf terakhir ke variabel\n",
    "            if w1_char!= '':\n",
    "                token_char.insert(0,w1_char)\n",
    "#           menambahkan huruf unik ke vocaulary\n",
    "            for char in token_char:\n",
    "                if char not in vocab_dict_char:\n",
    "                    vocab_dict_char[char] = 1\n",
    "                else:\n",
    "                    vocab_dict_char[char]+= 1\n",
    "#           token untuk quadgrams\n",
    "            temp2_char = list(ngrams(token_char,4))\n",
    "#           menghitung frekuensi dari bigram\n",
    "            for t in temp0_char:\n",
    "                sen_char = ''.join(t)\n",
    "                bi_dict_char[sen_char] += 1\n",
    "#           menghitung frekuensi dari trigram\n",
    "            for t in temp1_char:\n",
    "                sen_char = ''.join(t)\n",
    "                tri_dict_char[sen_char] += 1\n",
    "#           menghitung frekuensi dari quadgram\n",
    "            for t in temp2_char:\n",
    "                sen_char = ''.join(t)\n",
    "                quad_dict_char[sen_char] += 1\n",
    "#           menghitung panjang token\n",
    "            n_char = len(token_char)\n",
    "#           menambahkan kalimat ke variabel\n",
    "            if (n_char -3) >= 0:\n",
    "                w1_char = token_char[n_char -3]\n",
    "            if (n_char -2) >= 0:\n",
    "                w2_char = token_char[n_char -2]\n",
    "            if (n_char -1) >= 0:\n",
    "                w3_char = token_char[n_char -1]\n",
    "    return word_len_char\n",
    "\n",
    "# membuat dict untuk menyimpan probabilitas kalimat trigrams\n",
    "def findTrigramProbGT(vocab_dict, bi_dict, tri_dict, tri_prob_dict, nc_dict, k):\n",
    "    V = len(vocab_dict)\n",
    "    for tri in tri_dict:\n",
    "#       membagi kalimat trigrams menjadi perkata\n",
    "        tri_token = tri.split()\n",
    "#       membuat kalimat bigram dari kalimat trigrams\n",
    "        bi_sen = ' '.join(tri_token[:2])\n",
    "        tri_count = tri_dict[tri]\n",
    "        bi_count = bi_dict[bi_sen]\n",
    "#       menggunakan good turing smoothing\n",
    "        if tri_dict[tri] <= k or (tri not in tri_dict):\n",
    "            tri_count = findGoodTuringAdjustCount( tri_dict[tri], k, nc_dict)\n",
    "        if bi_dict[bi_sen] <= k or (bi_sen not in bi_dict):\n",
    "            bi_count = findGoodTuringAdjustCount( bi_dict[bi_sen], k, nc_dict)\n",
    "#       menghitung probabilitas trigram dengan membagi kalimat trigram dengan bigram\n",
    "        prob = tri_count / bi_count       \n",
    "#       menyimpan probabilitas trigrams ke dict\n",
    "        if bi_sen not in tri_prob_dict:\n",
    "            tri_prob_dict[bi_sen] = []\n",
    "            tri_prob_dict[bi_sen].append([prob,tri_token[-1]])\n",
    "        else:\n",
    "            tri_prob_dict[bi_sen].append([prob,tri_token[-1]])\n",
    "    prob = None\n",
    "    tri_token = None\n",
    "    bi_sen = None\n",
    "# membuat dict untuk menyimpan probabilitas kalimat bigrams\n",
    "def findBigramProbGT(vocab_dict, bi_dict, bi_prob_dict, nc_dict, k):\n",
    "    V = len(vocab_dict)\n",
    "    bigram = []\n",
    "    bigram_prob = []\n",
    "    for bi in bi_dict:\n",
    "#       membagi kaliamat bigrams menjadi perkata\n",
    "        bi_token = bi.split()\n",
    "        bigram.append(bi)\n",
    "#       membuat kalimat unigrams dari kalimat bigrams\n",
    "        unigram = bi_token[0]\n",
    "        bi_count = bi_dict[bi]\n",
    "        uni_count = vocab_dict[unigram]    \n",
    "#       menggunakan goot turing smoothing\n",
    "        if bi_dict[bi] <= k or (bi not in bi_dict):\n",
    "            bi_count = findGoodTuringAdjustCount( bi_dict[bi], k, nc_dict)\n",
    "        if vocab_dict[unigram] <= k or (unigram not in vocab_dict):\n",
    "            uni_count = findGoodTuringAdjustCount( vocab_dict[unigram], k, nc_dict)\n",
    "#       menghitung probabilitas bigram dengan membagi kalimat bigram dengan unigram\n",
    "        prob = bi_count / uni_count\n",
    "        bigram_prob.append(prob)\n",
    "#       menyimpan probabilitas bigrams ke dict\n",
    "        if unigram not in bi_prob_dict:\n",
    "            bi_prob_dict[unigram] = []\n",
    "            bi_prob_dict[unigram].append([prob,bi_token[-1]])\n",
    "        else:\n",
    "            bi_prob_dict[unigram].append([prob,bi_token[-1]])\n",
    "    prob = None\n",
    "    bi_token = None\n",
    "    unigram = None\n",
    "\n",
    "# membuat dict untuk menyimpan probabilitas karakter trigrams\n",
    "def findCharTrigramProbGT(vocab_dict_char, bi_dict_char, tri_dict_char, tri_prob_dict_char, nc_dict_char, k):\n",
    "    V = len(vocab_dict_char)\n",
    "    trigram = []\n",
    "    trigram_prob = []    \n",
    "    for tri_char in tri_dict_char:\n",
    "#       membagi kaliamat trigrams menjadi perhuruf\n",
    "        tri_token_char = tri_char.split()\n",
    "        char = ' '.join(tri_token_char[0])\n",
    "        tri_tokenc = char.split()\n",
    "#       membuat huruf bigram dari huruf trigrams\n",
    "        bi_sen_char = ''.join(tri_tokenc[:2])\n",
    "        tri_count_char = tri_dict_char[tri_char]\n",
    "        bi_count_char = bi_dict_char[bi_sen_char]    \n",
    "#       menggunakan goot turing smoothing\n",
    "        if tri_dict_char[tri_char] <= k or (tri_char not in tri_dict_char):\n",
    "            tri_count_char = findGoodTuringAdjustCount( tri_dict_char[tri_char], k, nc_dict_char)\n",
    "        if bi_dict_char[bi_sen_char] <= k or (bi_sen_char not in bi_dict_char):\n",
    "            bi_count_char = findGoodTuringAdjustCount( bi_dict_char[bi_sen_char], k, nc_dict_char)\n",
    "#       menghitung probabilitas trigram dengan membagi huruf trigram dengan bigram\n",
    "        prob_char = tri_count_char / bi_count_char\n",
    "        trigram_prob.append(prob_char)\n",
    "        tri_prob_dict_char[tri_char] = prob_char        \n",
    "#       menyimpan probabilitas trigrams ke dict\n",
    "        if bi_sen_char not in tri_prob_dict_char:\n",
    "            tri_prob_dict_char[bi_sen_char] = []\n",
    "            tri_prob_dict_char[bi_sen_char].append([prob_char,tri_token_char[-1]])\n",
    "        else:\n",
    "            tri_prob_dict_char[bi_sen_char].append([prob_char,tri_token_char[-1]])\n",
    "    prob_char = None\n",
    "    tri_token_char = None\n",
    "    bi_sen_char = None\n",
    "# membuat dict untuk menyimpan probabilitas karakter bigrams\n",
    "def findCharBigramProbGT(vocab_dict_char, bi_dict_char, bi_prob_dict_char, nc_dict_char, k):\n",
    "    #vocabulary size\n",
    "    V = len(vocab_dict_char)\n",
    "    bigram = []\n",
    "    bigram_prob = []\n",
    "    for bi_char in bi_dict_char:\n",
    "#       membagi kaliamat bigrams menjadi perhuruf\n",
    "        bi_token_char = bi_char.split()\n",
    "        bigram.append(bi_char)\n",
    "#       membuat huruf unigram dari huruf bigrams\n",
    "        unigram_char = bi_token_char[0][0]\n",
    "        test.append(unigram_char)\n",
    "        bi_count_char = bi_dict_char[bi_char]\n",
    "        uni_count_char = vocab_dict_char[unigram_char]\n",
    "#       menggunakan goot turing smoothing\n",
    "        if bi_dict_char[bi_char] <= k or (bi_char not in bi_dict_char):\n",
    "            bi_count_char = findGoodTuringAdjustCount( bi_dict_char[bi_char], k, nc_dict_char)\n",
    "        if vocab_dict_char[unigram_char] <= k or (unigram_char not in vocab_dict_char):\n",
    "            uni_count_char = findGoodTuringAdjustCount( vocab_dict_char[unigram_char], k, nc_dict_char)\n",
    "#       menghitung probabilitas bigram dengan membagi huruf bigram dengan unigram\n",
    "        prob_char = bi_count_char / uni_count_char\n",
    "        bigram_prob.append(prob_char)\n",
    "        bi_prob_dict_char[bi_char] = prob_char\n",
    "#       menyimpan probabilitas bigrams ke dict\n",
    "        if unigram_char not in bi_prob_dict_char:\n",
    "            bi_prob_dict_char[unigram_char] = []\n",
    "            bi_prob_dict_char[unigram_char].append([prob_char,bi_token_char[-1]])\n",
    "        else:\n",
    "            bi_prob_dict_char[unigram_char].append([prob_char,bi_token_char[-1]])\n",
    "    prob_char = None\n",
    "    bi_token_char = None\n",
    "    unigram_char = None\n",
    "\n",
    "# untuk mengurutkan probabilitas dari yang terbesar\n",
    "def sortProbWordDict(bi_prob_dict, tri_prob_dict, quad_prob_dict):\n",
    "    for key in bi_prob_dict:\n",
    "        if len(bi_prob_dict[key])>1:\n",
    "            bi_prob_dict[key] = sorted(bi_prob_dict[key],reverse = True)\n",
    "    for key in tri_prob_dict:\n",
    "        if len(tri_prob_dict[key])>1:\n",
    "            tri_prob_dict[key] = sorted(tri_prob_dict[key],reverse = True)\n",
    "    for key in quad_prob_dict:\n",
    "        if len(quad_prob_dict[key])>1:\n",
    "            quad_prob_dict[key] = sorted(quad_prob_dict[key],reverse = True)[:2]\n",
    "\n",
    "# untuk mengambil inputan\n",
    "def takeInput():\n",
    "    cond = False\n",
    "    while(cond == False):\n",
    "        sen = input('Enter the string\\n')\n",
    "        temp = sen.split()\n",
    "        if len(temp) < 0:\n",
    "            print(\"Please enter atleast 1 words !\")\n",
    "        else:\n",
    "            cond = True\n",
    "            temp = temp[:]\n",
    "    sen = \" \".join(temp)\n",
    "    return sen\n",
    "# mencari adjusted count c* di good turing smoothing\n",
    "def findGoodTuringAdjustCount(c, k, nc_dict):\n",
    "    adjust_count = ( ( (( c + 1)*( nc_dict[c + 1] / nc_dict[c])) - ( c * (k+1) * nc_dict[k+1] / nc_dict[1]) ) /\n",
    "                     ( 1 - (( k + 1)*nc_dict[k + 1] / nc_dict[1]) )\n",
    "                   )\n",
    "    return adjust_count\n",
    "\n",
    "# mencari prediksi kalimat menggunakan backoff\n",
    "def doPredictionBackoffGT(input_sen, bi_dict, tri_dict, quad_dict, bi_prob_dict, tri_prob_dict, quad_prob_dict):\n",
    "    token = input_sen.split()\n",
    "    if input_sen in quad_prob_dict and quad_prob_dict[ input_sen ][0][0]>0:\n",
    "        print(\"quad\")\n",
    "        pred = quad_prob_dict[input_sen][0]\n",
    "    elif ' '.join(token[1:]) in tri_prob_dict and tri_prob_dict[' '.join(token[1:])][0][0]>0:\n",
    "        print(\"tri\")\n",
    "        pred = tri_prob_dict[ ' '.join(token[1:]) ][0]\n",
    "    elif ' '.join(token[2:]) in bi_prob_dict and bi_prob_dict[ ' '.join(token[2:]) ][0][0]>0:\n",
    "        print(\"bi\")\n",
    "        pred = bi_prob_dict[' '.join(token[2:])][0]\n",
    "    else:\n",
    "        print(\"kosong\")\n",
    "        pred = []\n",
    "    return pred\n",
    "\n",
    "# fungsi mencari kemungkiann kata dari kata singkatan\n",
    "def contained(pred,kata):\n",
    "    jumlahs = len(pred)\n",
    "    jumlaht = len(kata)\n",
    "    jumlah = 0\n",
    "    value = 0\n",
    "    i=0\n",
    "    j=0\n",
    "    n = \"\"\n",
    "    veri = 0\n",
    "#   untuk kata yang berulang seperti yaaaaaannnnggg menjadi yang\n",
    "    if len(kata) > 2: \n",
    "        for k in range(0,len(kata)):\n",
    "            if len(kata) > 0:\n",
    "                if k < len(kata)-1:\n",
    "                    if kata[k] != kata[k+1]:\n",
    "                        if value == 1:\n",
    "                            n = n + kata[k] + kata[k]\n",
    "                            veri = 1\n",
    "                            value = 0\n",
    "                        else: \n",
    "                            n = n + kata[k]\n",
    "                            veri = 1\n",
    "                            value = 0\n",
    "                    elif kata[k] == kata[k+1]:\n",
    "                        value+=1\n",
    "                        if k == len(kata)-2:\n",
    "                            if value == 1:\n",
    "                                n = n + kata[k]\n",
    "        if veri != 0:\n",
    "            n = n + kata[len(kata)-1]\n",
    "            kata = n\n",
    "            jumlaht = len(kata)\n",
    "#   menghitung berapa kalimat singkatan yang mengandung kalimt prediksi\n",
    "    while i < jumlaht:\n",
    "        while j < jumlahs:\n",
    "            if kata[i]==pred[j]:\n",
    "                jumlah+=1\n",
    "                j+=1\n",
    "                break\n",
    "            j+=1\n",
    "        i+=1    \n",
    "#   mengembalikan nilai true apa bila semua mengandung kata tersebut\n",
    "    if jumlah >= jumlaht:\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "# membuat gui\n",
    "# membuat form\n",
    "def makeform(root, field):\n",
    "    print(field)\n",
    "    row = Frame(root)\n",
    "    lab = Label(row, width=22, text=field+\": \", anchor='w')\n",
    "    ent = Text(row, height=5)\n",
    "    row.pack(side=TOP, \n",
    "             fill=X, \n",
    "             padx=5, \n",
    "             pady=5)\n",
    "    lab.pack(side=LEFT)\n",
    "    ent.pack(side=RIGHT, \n",
    "             expand=YES, \n",
    "             fill=X)\n",
    "    entries[field] = ent\n",
    "    return entries\n",
    "# membuat tabel\n",
    "def maketable(root,kataslang,prediksi):\n",
    "    b = Frame(root)\n",
    "    b.pack(side=TOP, \n",
    "             fill=X, \n",
    "             padx=5, \n",
    "             pady=5)\n",
    "    n = len(kataslang)\n",
    "    count = 0\n",
    "    height = 8\n",
    "    width = 2\n",
    "    for i in range(n): #Rows\n",
    "        for j in range(width): #Columns\n",
    "            tab = Entry(b, text=\"\")\n",
    "            if j == 0:\n",
    "                tab.insert(0, kataslang[count])\n",
    "            else:\n",
    "                tab.insert(0, prediksi[count])\n",
    "            tab.grid(row=i, column=j)\n",
    "        count+=1\n",
    "    return tab\n",
    "            \n",
    "def clicked(entries,senInput):\n",
    "    entries['Output'].insert('0.0', senInput[:] )\n",
    "token = []\n",
    "kata = []\n",
    "index = []\n",
    "wrong = []\n",
    "input_teks = []\n",
    "test = []\n",
    "true = []\n",
    "prediksi = []\n",
    "kataslang = []\n",
    "dataCsv = []\n",
    "senInput = []\n",
    "entries = {}\n",
    "from tkinter import *\n",
    "colomn_wrong = []\n",
    "colomn_pred = []\n",
    "colomn_prob = []\n",
    "if __name__ == '__main__':\n",
    "    vocab_dict = defaultdict(int)          #untuk membuat kalimat yang unik menjadi ada frekuensi   \n",
    "    bi_dict = defaultdict(int)             #untuk menyimpan 2 kalimat \n",
    "    tri_dict = defaultdict(int)            #untuk menyimpan 3 kalimat \n",
    "    quad_dict = defaultdict(int)           #untuk menyimpan 4 kalimat \n",
    "    vocab_dict_char = defaultdict(int)          \n",
    "    bi_dict_char = defaultdict(int)             \n",
    "    tri_dict_char = defaultdict(int)           \n",
    "    quad_dict_char = defaultdict(int)           \n",
    "    quad_prob_dict = OrderedDict()              \n",
    "    tri_prob_dict = OrderedDict()\n",
    "    bi_prob_dict = OrderedDict()\n",
    "    quad_prob_dict_char = OrderedDict()              \n",
    "    tri_prob_dict_char = OrderedDict()\n",
    "    bi_prob_dict_char = OrderedDict() \n",
    "    list_pred = []\n",
    "#   koneksi ke db\n",
    "    database = \"C:\\\\db\\\\korpus.db\"\n",
    "    conn = create_connection(database)\n",
    "#   membuka korpus kecil\n",
    "    train_file = 'Kecilkorpus.txt'\n",
    "#   menjalankan fungsi loadcorpus dan loadcorpuschar\n",
    "    token_len = loadCorpus(train_file, bi_dict, tri_dict, quad_dict, vocab_dict)\n",
    "    token_len_char = loadCorpusChar(train_file, bi_dict_char, tri_dict_char, quad_dict_char, vocab_dict_char)\n",
    "    k = 5\n",
    "    V = len(vocab_dict)\n",
    "    tri_nc_dict = findFrequencyOfFrequencyCount(tri_dict, k, 3, V, len(tri_dict))\n",
    "    bi_nc_dict = findFrequencyOfFrequencyCount(bi_dict, k, 2, V, len(bi_dict))\n",
    "    uni_nc_dict = findFrequencyOfFrequencyCount(bi_dict, k, 1, V, len(vocab_dict))\n",
    "    tri_nc_dict_char = findFrequencyOfFrequencyCount(tri_dict_char, k, 3, V, len(tri_dict_char))\n",
    "    bi_nc_dict_char = findFrequencyOfFrequencyCount(bi_dict_char, k, 2, V, len(bi_dict_char))\n",
    "    uni_nc_dict_char = findFrequencyOfFrequencyCount(bi_dict_char, k, 1, V, len(vocab_dict_char))\n",
    "#   membuat dic probabilitas bigram, trigram, charbigram, chartrigram\n",
    "    findBigramProbGT(vocab_dict, bi_dict, bi_prob_dict, bi_nc_dict, k)\n",
    "    findTrigramProbGT(vocab_dict, bi_dict, tri_dict, tri_prob_dict, tri_nc_dict, k) \n",
    "    findCharBigramProbGT(vocab_dict_char, bi_dict_char, bi_prob_dict_char, bi_nc_dict_char, k)\n",
    "    findCharTrigramProbGT(vocab_dict_char, bi_dict_char, tri_dict_char, tri_prob_dict_char, tri_nc_dict_char, k)\n",
    "    sortProbWordDict(bi_prob_dict, tri_prob_dict, quad_prob_dict)\n",
    "    entries = {}\n",
    "    root = Tk()\n",
    "    ents = makeform(root, 'Input')\n",
    "    b1 = Button(root, text='Normalisasi', command=(lambda e=ents: main(e,root)))\n",
    "    b1.pack(side=TOP, fill=X, padx=5, pady=5)\n",
    "    ents = makeform(root, 'Output') \n",
    "    root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}